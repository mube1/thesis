# Improving Knowledge Distillation
Improving KD via reducing regularization.


### To train


+ install requirments.txt <br/>
+ run python train.py with the following arguments : <br/>
  > teacher
  > student
  > learning rate
  > pruning rate
  > pruning mode
  > batch size
  > epochs
  > optimizer
  > temperature
  > etc ..
  

   

